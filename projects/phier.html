<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <!-- <meta name="description" content="DESCRIPTION META TAG"> -->
  <!-- <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/> -->
  <!-- <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/> -->
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/images/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <!-- <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG"> -->
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <!-- <meta name="twitter:image" content="static/images/your_twitter_banner_image.png"> -->
  <!-- <meta name="twitter:card" content="summary_large_image"> -->
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="state classification visual reasoning">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>PHIER</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>

  <style>
    .texttt {
      font-family: 'Courier New', monospace;
    }
  </style>
  
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Predicate Hierarchies Improve <br> Few-Shot State Classification</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://emilyzjin.github.io/" target="_blank">Emily Jin</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="https://stanford.edu/~joycj/" target="_blank">Joy Hsu</a><sup>*</sup>,</span>
                  <span class="author-block">
                    <a href="https://jiajunwu.com/" target="_blank">Jiajun Wu</a>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Stanford University<br>ICLR 2025</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <!-- <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank" -->
                        <a target="_blank"
                            class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper (coming soon!)</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code (coming soon!)</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv (coming soon!)</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Teaser video-->
<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <source src="static/videos/banner_video.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2>
    </div>
  </div>
</section> -->
<!-- End teaser video -->

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="item">
            <img src="static/images/pull.png" alt="Pull Figure"/>
          </div> 
        </div>
    </div>
  </div>
</section> 

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            State classification of objects and their relations is core to many long-horizon
            tasks, particularly in robot planning and manipulation. However, the combinatorial
            explosion of possible object-predicate combinations, coupled with the need to adapt
            to novel real-world environments, makes it a desideratum for state classification
            models to generalize to novel queries with few examples. To this end, we propose
            PHIER, which leverages predicate hierarchies to generalize effectively in few-shot
            scenarios. PHIER uses an object-centric scene encoder, self-supervised losses that
            infer semantic relations between predicates, and a hyperbolic distance metric that
            captures hierarchical structure; it learns a structured latent space of image-predicate
            pairs that guides reasoning over state classification queries. We evaluate PHIER
            in the CALVIN and BEHAVIOR robotic environments and show that PHIER
            significantly outperforms existing methods in few-shot, out-of-distribution state
            classification, and demonstrates strong zero- and few-shot generalization from
            simulated to real-world tasks. Our results demonstrate that leveraging predicate
            hierarchies improves performance on state classification tasks with limited data.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->



<!-- Youtube video --> 
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">State Classification</h2>
          <div class="content has-text-justified">
            <p>
              State classification of objects and relations is essential for a plethora of tasks, from scene understanding to robot planning and 
              manipulation. Many such long-horizon tasks require accurate and varied state predictions for entities in scenes. For example, planning 
              for “setting up the table” requires classifying whether the cup is <span class="texttt">NextTo</span> the plate, whether the utensils are 
              <span class="texttt">OnTop</span> of the table, and whether the microwave is <span class="texttt">Open</span>. 
              <br><br>
              The goal of state classification is to precisely answer such queries about specific entities in an image, and determine whether they 
              satisfy particular conditions across a range of attributes and relations.
              <br><br>
              However, the combinatorial space of objects (e.g., cup, plate, microwave) and predicates (e.g., <span class="texttt">NextTo</span>, <span class="texttt">OnTop</span>, 
              <span class="texttt">Open</span>) gives rise to an explosion of possible object-predicate combinations that is intractable to obtain corresponding 
              training data for. In addition, real-world systems operating in dynamic environments must generalize to queries with novel predicates, 
              often with only a few examples. Hence, an essential but difficult consideration for state classification models is to quickly learn to 
              adapt to out-of-distribution queries. 
            </p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End youtube video -->

<div class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Method</h2>
        <div class="item">
          <img src="static/images/systems.png" alt="Systems Figure"/>
        </div> 
        <div class="content has-text-justified">
          <br>
          <p>
            We propose PHIER, a state classification model that leverages the hierarchical structure between predicates to few-shot generalize 
            to novel queries. At the core of PHIER is an image-predicate latent space trained to encode the relationship between pairwise predicates.
            Let us consider the predicates, <span class="texttt">OnRight</span> and <span class="texttt">OnLeft</span> they describe opposite spatial relationships between objects, 
            they are closely related semantically, as assessing them relies on the same underlying features. PHIER enforces image-predicate 
            representations conditioned on these predicates to lie closer to one another. In addition, there exist predicate pairs with more complex 
            relationships, such as <span class="texttt">OnRight</span> and <span class="texttt">NextTo</span>. We see that <span class="texttt">OnRight</span> is a more specific case of 
            <span class="texttt">NextTo</span>—verifying <span class="texttt">OnRight</span> involves recognizing whether the objects are <span class="texttt">NextTo</span> each other. Features 
            relevant to the higher-level predicate <span class="texttt">NextTo</span> are therefore useful for reasoning about the lower-level predicate 
            <span class="texttt">OnRight</span>. PHIER encodes this predicate hierarchy to allow generalizable state classification.
            <br>
            <br>
            <br>
            To perform state classification, PHIER first localizes relevant objects in the input image based on a given query, then leverages an 
            inferred predicate hierarchy to structure its reasoning over the scene. This is achieved through three main components:
            <ul>
              <li><strong>Object-Centric Scene Encoder:</strong> Localizes regions of the image corresponding to relevant entities, ensuring that 
                the model faithfully identifies relevant entities and then learns to focus on their key features for the given predicate's classification.</li>
              <li><strong>Self-Supervised Losses:</strong> Encourage the model to encode pairwise predicate relations in its latent space (e.g. 
                <span class="texttt">OnRight</span> and <span class="texttt">NextTo</span> are encouraged to be close). The pairwise relations are inferred from language using a LLM. </li>

              <li><strong>Hyperbolic Distance Metric:</strong> Encodes the predicate hierarchy in hyperbolic space, leveraging its exponentially growing distances suitable to enable PHIER to effectively model tree-like structure in continuous space. </li>
          </p>
        </div>
      </div>
    </div>
  </div>
</div>
</section>

<div class="hero-body">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Results</h2>
        <div class="content has-text-justified">
          <p> 
            We evaluate PHIER on the state classification task in two robotics environments, CALVIN and BEHAVIOR. Beyond the standard test settings, we focus on few-shot, out-of-distribution tasks involving unseen object-predicate combinations and novel predicates.
            PHIER significantly outperforms existing methods on out-of-distribution tasks, including both supervised approaches trained on the same amount of data and inference-only vision-language models (VLMs) trained on large corpora of real-world examples. 
            <br><br>
            PHIER improves upon the top-performing prior work in out-of-distribution tasks by 22.5 percent points on CALVIN and 8.3 percent points on BEHAVIOR.
          </p>
        </div>   

        <div id="results-carousel" class="carousel results-carousel">
          <div class="item">
            <img src="static/images/ood_calvin.png" alt="CALVIN Results Figure"/>
          </div>           
          <div class="item">
            <img src="static/images/ood_behavior.png" alt="BEHAVIOR Results Figure"/>
          </div>        
        </div>
        <div class="content has-text-justified">
          <br>
          <p> 
            Notably, trained solely on simulated data, PHIER also outperforms supervised baselines on
            few-shot generalization to real-world state classification tasks by 10 percent points.
            <!-- , while performing comparably to VLMs trained on vast amounts of real-world data. -->
          </p>
        </div>         
        <!-- <div class="item" style="width: 90%; margin: 0 auto;"> -->
        <div class="item">
          <img src="static/images/real_world.png" alt="Real World Results Figure"/>
        </div> 
        <div class="content has-text-justified">
          <br>
          <p> 
            Overall, we see PHIER as a promising solution to few-shot state classification, enabling generalization by 
            leveraging representations grounded in predicate hierarchies.
          </p>
        </div>                 
      </div>
    </div>
  </div>
</div>
</section>

<!--BibTex citation -->
  <!-- <section class="section" id="BibTeX">
    <div class="container is-max-desktop">
      <h2 class="title">BibTeX</h2>
      <pre><span class="texttt">BibTex Code Here</span></pre>
    </div>
</section> -->
<!--End BibTex citImage cation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            <!-- You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative -->
            <!-- Commons Attribution-ShareAlike 4.0 International License</a>. -->
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
