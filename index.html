<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Emily Jin</title>

    <meta name="author" content="Emily Jin">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:70%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Emily Jin
                </p>
                <p>Hi — I'm Emily! I'm a first-year Ph.D. student in Computer Science at Stanford University. My research is graciously funded by the NDSEG Fellowship, and I was also honored to receive the NSF GRFP.
                </p>
                <p>
			Previously, I earned my B.S. in Mathematics and M.S. in Computer Science at Stanford. During this time, I had the privilege of working with Prof. <a href="https://jiajunwu.com/">Jiajun Wu</a>, Prof. <a href="https://cicl.stanford.edu/member/tobias_gerstenberg/">Tobias Gerstenberg</a>, and Prof. <a href="https://profiles.stanford.edu/fei-fei-li">Li Fei-Fei</a> on projects exploring visual reasoning and its intersection with cognitive science.  
		</p>       

                <p style="text-align:center">
                  <a href="mailto:emilyjin@stanford.edu">Email</a> &nbsp;/&nbsp;
<!-- 		  <a href="pdfs/Emily_Jin_CV.pdf" target="_blank">CV</a> &nbsp;/&nbsp; -->
<!-- 		  <a href="pdfs/research_statement.pdf" target="_blank">Research Statement</a> &nbsp;/&nbsp;						 -->
                  <a href="https://scholar.google.com/citations?user=-MTq9O0AAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/emilyzjin/">Github</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/emily-jin-020"> LinkedIn </a>
                  <!-- <a href="https://twitter.com/emilyzjin">Twitter</a> &nbsp;/&nbsp; -->
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/headshot_new.png"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/headshot_new.png" class="hoverZoomLink"></a>
              </td>
            </tr>

          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
			My research interests lie in machine learning and computer vision, with a focus on developing machines that leverage a <i>structured understanding of the visual world</i> to <i>reason with human-like flexibility.</i> 
			Drawing inspiration from human cognition, I aim to explore how machines can (1) learn structured visual representations at the "right" level of abstraction, and (2) perform complex, real-world reasoning grounded in these representations.                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr>
      <td style="padding:5%;width:30%;vertical-align:middle">
        <div class="one" style="display: grid; place-items: center;">
          <div class="two" id='scene_image'><video  width=100% muted autoplay loop>
          <source src="images/factored_scenes.png" type="image">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/factored_scenes.png' width=100%>
        </div> 
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle">
        <a href="https://arxiv.org/pdf/2510.10292">
          <span class="papertitle">From Programs to Poses: Factored Real-World Scene Generation via Learned Program Libraries
</span>
        </a>
        <br>
        <a href="https://stanford.edu/~joycj/">Joy Hsu</a>,
        <strong>Emily Jin</strong>,	      
        <a href=https://jiajunwu.com/">Jiajun Wu</a>,
        <a href=https://research.adobe.com/person/niloy-mitra/">Niloy Mitra</a>	      
        <br>
        <em>NeurIPS 2025</em>
        <br>
        <a href="https://stanford.edu/~joycj/projects/factoredscenes_neurips_2025.html">project page</a> 
        /
        <a href="https://arxiv.org/pdf/2510.10292">paper</a>
        <p></p> 
      </td>
    </tr>
	
	<tr bgcolor="#e8f7f8">
      <td style="padding:5%;width:30%;vertical-align:middle">
        <div class="one" style="display: grid; place-items: center;">
          <div class="two" id='phier'><video  width=100% muted autoplay loop>
          <source src="images/phier.png" type="image">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/phier.png' width=100%>
        </div> 
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle">
        <a>
          <span class="papertitle">Predicate Hierarchies Improve Few-Shot State Classification
	  </span>
        </a>
        <br>
        <strong>Emily Jin</strong>*,
        <a href="https://stanford.edu/~joycj/">Joy Hsu</a>*,
        <a href=https://jiajunwu.com/">Jiajun Wu</a>
        <br>
        <em>ICLR, 2025</em>
	<br>
	<a href="projects/phier.html">project page</a>
	/
        <a href="https://www.arxiv.org/abs/2502.12481">paper</a>
        /
        <a href="https://github.com/emilyzjin/phier">code</a>	      
        <p></p> 
      </td>
    </tr>
<br>
    <tr bgcolor="#e8f7f8">
      <td style="padding:5%;width:30%;vertical-align:middle">
        <div class="one" style="display: grid; place-items: center;">
          <div class="two" id='marple_image'><video  width=100% muted autoplay loop>
          <source src="images/marple.png" type="image">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/marple.png' width=100%>
        </div> 
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle">
        <a href="https://emilyzjin.github.io/projects/marple.html">
          <span class="papertitle">MARPLE: A Benchmark for Long-Horizon Inference 
</span>
        </a>
        <br>
        <strong>Emily Jin</strong>*,
        <a href="https://www.linkedin.com/in/zhuoyi-huang">Zhuoyi Huang</a>*,
        <a href="https://janphilippfranken.github.io/">Jan-Philipp Fränken</a>,
        <a href="https://weiyuliu.com/">Weiyu Liu</a>,     
        <a href="https://www.linkedin.com/in/hannah-cha">Hannah Cha</a>,   
				<a href="https://www.erikbrockbank.com/">Erik Brockbank</a>,
        <a href="https://sarahawu.github.io/">Sarah A. Wu</a>,
        <a href="https://ai.stanford.edu/~zharu/">Ruohan Zhang</a>,
        <a href=https://jiajunwu.com/">Jiajun Wu</a>,
        <a href="https://cicl.stanford.edu/member/tobias_gerstenberg/">Tobias Gerstenberg</a> 	
        <br>
        <em>NeurIPS Datasets and Benchmarks Track, 2024</em>
        <br> 
        <a href="https://emilyzjin.github.io/projects/marple.html">project page</a>
        /
        <a href="https://arxiv.org/abs/2410.01926">paper</a>
        /
        <a href="https://github.com/emilyzjin/marple">code</a>
        <p></p> 
      </td>
    </tr>	
    <tr>
      <td style="padding:5%;width:30%;vertical-align:middle">
        <div class="one" style="display: grid; place-items: center;">
          <div class="two" id='whodunnit_image'><video  width=100% muted autoplay loop>
          <source src="images/whodunnit.png" type="image">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/whodunnit.png' width=100%>
        </div> 
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle">
        <a href="https://cicl.stanford.edu/papers/wu2024whodunnit.pdf">
          <span class="papertitle">Whodunnit? Inferring What Happened From Multimodal Evidence
</span>
        </a>
        <br>
				<a href="https://sarahawu.github.io/">Sarah A. Wu</a>*,
        <a href="https://www.erikbrockbank.com/">Erik Brockbank</a>*,
        <a href="https://www.linkedin.com/in/hannah-cha">Hannah Cha</a>,
        <a href="https://janphilippfranken.github.io/">Jan-Philipp Fränken</a>,
        <strong>Emily Jin</strong>,
        <a href="https://www.linkedin.com/in/zhuoyi-huang">Zhuoyi Huang</a>,
        <a href="https://weiyuliu.com/">Weiyu Liu</a>,
        <a href="https://ai.stanford.edu/~zharu/">Ruohan Zhang</a>,
        <a href=https://jiajunwu.com/">Jiajun Wu</a>,
        <a href="https://cicl.stanford.edu/member/tobias_gerstenberg/">Tobias Gerstenberg</a> 	
        <br>
        <em>CogSci</em>, 2024
        <br>
        <a href="https://osf.io/preprints/psyarxiv/gpzms">preprint</a>
        /
        <a href="https://cicl.stanford.edu/papers/wu2024whodunnit.pdf">pdf</a>
        /
        <a href="https://cicl.stanford.edu/posters/wu2024whodunnit-poster.pdf">poster</a>
        /
        <a href="https://github.com/cicl-stanford/whodunnit_multimodal_inference">code</a>
        <p></p> 
      </td>
    </tr>
	
    <tr>
      <td style="padding:5%;width:30%;vertical-align:middle">
        <div class="one" style="display: grid; place-items: center;">
          <div class="two" id='mini_bh_image'><video  width=100% muted autoplay loop>
          <source src="images/mini_bh.png" type="image">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/mini_bh.png' width=100%>
        </div> 
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle">
        <a href="https://github.com/StanfordVL/mini_behavior">
          <span class="papertitle">Mini-BEHAVIOR: A Procedurally Generated Benchmark for Long-horizon Decision-Making in Embodied AI
</span>
        </a>
        <br> 
        <strong>Emily Jin</strong>*,
        <a href="https://jiahenghu.github.io/">Jiaheng Hu</a>*,
        <a href="https://www.linkedin.com/in/zhuoyi-huang">Zhuoyi Huang</a>,
        <a href="https://ai.stanford.edu/~zharu/">Ruohan Zhang</a>,
        <a href="https://jiajunwu.com/">Jiajun Wu</a>,
        <a href="https://profiles.stanford.edu/fei-fei-li">Li Fei-Fei</a>,
        <a href="https://robertomartinmartin.com/"> Roberto Martín-Martín</a>
        <br>
        <em>NeurIPS GenPlan Workshop & NeurIPS ALOE Workshop</em>, 2023
        <br> 
        <a href="https://arxiv.org/abs/2310.01824">paper</a>
        /
        <a href="https://neurips.cc/media/PosterPDFs/NeurIPS%202023/79902.png?t=1702417636.9499474">poster</a>
        /
        <a href="https://github.com/StanfordVL/mini_behavior">code</a>
        <p></p> 
      </td>
    </tr> 

    <tr>
      <td style="padding:5%;width:30%;vertical-align:middle">
        <div class="one" style="display: grid; place-items: center;">
          <div class="two" id='sgm_image'><video  width=100% muted autoplay loop>
          <source src="images/sgm.png" type="image">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/sgm.png' width=100%>
        </div> 
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle">
        <a href=https://www.scenegraphmemory.com/">
          <span class="papertitle">Modeling Dynamic Environments with Scene Graph Memory
</span>
        </a>
        <br>  
        <a>Andrey Kurenkov</a>*,
        <a href="https://mlingelbach.com/">Michael Lingelbach</a>,
        <a href="https://tanmay-agarwal.com/">Tanmay Agarwal</a>,
        <strong>Emily Jin</strong>,
        <a href="https://www.chengshuli.me/">Chengshu Li</a>,
        <a href="https://ai.stanford.edu/~zharu/">Ruohan Zhang</a>,
        <a href="https://profiles.stanford.edu/fei-fei-li">Li Fei-Fei</a>,
        <a href="https://jiajunwu.com/">Jiajun Wu</a>,
        <a href="https://aicenter.stanford.edu/people/silvio-savarese">Silvio Savarese</a>
        <a href="https://robertomartinmartin.com/"> Roberto Martín-Martín</a>
        <br>
        <em>ICML</em>, 2023
        <br> 
        <a href="https://www.scenegraphmemory.com/">project page</a>
        /
        <a href="https://arxiv.org/abs/2305.17537">paper</a>
        /
        <a href="https://github.com/andreykurenkov/modeling_env_dynamics">code</a>
        <p></p> 
      </td>
    </tr> 

    <tr>
      <td style="padding:5%;width:30%;vertical-align:middle">
        <div class="one" style="display: grid; place-items: center;">
          <div class="two" id='sgm_image'><video  width=100% muted autoplay loop>
          <source src="images/moma.png" type="image">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/moma.png' width=100%>
        </div> 
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle">
        <a href="https://moma.stanford.edu/#/">
          <span class="papertitle">MOMA-LRG: Language-Refined Graphs for Multi-Object Multi-Actor Activity Parsing
</span>
        </a>
        <br>  
        <a href="https://alan.vision/"> Zelun Luo</a>,
        <a href="https://zanedurante.github.io/"> Zane Durante</a>*,
        <a href="https://linden-li.github.io/">Linden Li</a>*,
        <a>Wanze Xie</a>,
        <a>Ruochen Liu</a>,
        <strong>Emily Jin</strong>,
        <a href="https://www.linkedin.com/in/zhuoyi-huang"> Zhuoyi Huang</a>,
        <a > Lun Yu Li</a>,
        <a href="https://ai.stanford.edu/~zharu/">Ruohan Zhang</a>,
        <a href="https://jiajunwu.com/">Jiajun Wu</a>,
        <a href="https://www.niebles.net/">Juan Carlos Niebles</a>,
        <a href="https://stanford.edu/~eadeli/">Ehsan Adeli</a>,      
        <a href="https://profiles.stanford.edu/fei-fei-li">Li Fei-Fei</a>
        <br>
        <em>NeurIPS Datasets and Benchmarks Track</em>, 2022
        <br> 
        <a href="https://moma.stanford.edu/#/">project page</a>
        /
        <a href="https://papers.nips.cc/paper_files/paper/2022/hash/22c16986b2f50af520f56dc34d91e403-Abstract-Datasets_and_Benchmarks.html">paper</a>
        /
        <a href="https://github.com/StanfordVL/moma/">code</a>
        <p></p> 
      </td>
    </tr>     

    </tbody></table>

          
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Teaching & Outreach</h2>
		<p>
		Over the years, I've been incredibly lucky to find support from inspiring mentors and inclusive communities. These experiences have motivated me to give back through teaching and outreach:
		</p>
		      
                <a href="https://hai.stanford.edu/stanford-ai4all">Stanford AI4ALL.</a> 
                <br>
                Program Manager, 2020-2025.

                <br><br>		      

                <a href="https://cs231n.stanford.edu/">Stanford CS 231N.</a> Deep Learning for Computer Vision.
                <br>
                Course Assistant, Spring 2025.

                <br><br>
		      
                <a>Stanford CS 157.</a> Introduction to Logic.
                <br>
                Course Assistant, Fall 2024.

                <br><br>
		      
                <a href="https://www.treehacks.com/">Stanford TreeHacks</a> 
                <br>
                Organizer, 2021.

                <br><br>		      

                <a href="https://aihacks.com">AIHacks.</a> Southern California's first all-female high school hackathon.
                <br>
                Founder and Executive Director, 2019-2020 
                <br>
                Media: <a href="https://spectrumnews1.com/ca/la-west/news/2019/06/17/student-organizes-all-female-hackathon-to-address-ai-gender-gap#">Spectrum News</a>
                /
                <a href="https://www.dailynews.com/2019/06/17/a-north-hollywood-high-school-seniors-all-girl-hackathon-aimed-to-empower-her-peers/">Los Angeles Daily News</a>
              </td>
            </tr> 

          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Website source from <a href="https://jonbarron.info/">Jon Barron</a>. 
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
