<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Emily Jin</title>

    <meta name="author" content="Emily Jin">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:70%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Emily Jin
                </p>
                <p>Hi — I'm Emily! I am currently pursuing my B.S. in Mathematics & M.S. in Computer Science at Stanford University.
                </p>
                <p>
		I am a researcher in the <a href="https://svl.stanford.edu/">Stanford Vision and Learning Lab (SVL)</a>, where I am fortunate to conduct research on visual reasoning advised by Prof. <a href="https://jiajunwu.com/">Jiajun Wu</a>. In addition, I’ve had the wonderful opportunity to work with Prof. <a href="https://profiles.stanford.edu/fei-fei-li">Li Fei-Fei</a> and Prof. <a href="https://cicl.stanford.edu/member/tobias_gerstenberg/">Tobias Gerstenberg</a> on projects that explore different aspects of visual intelligence and their intersections with cognitive science. My research focuses on developing AI that <i>understands the structure of the visual world</i> and leverages this understanding to <i>reason with human-like flexibility.</i>
		</p>
                <p>
                 Beyond research, I’m passionate about advancing diversity in tech and have dedicated myself to creating engaging CS experiences for underrepresented communities.
                </p>		      
                <p style="text-align:center">
                  <a href="mailto:emilyjin@stanford.edu">Email</a> &nbsp;/&nbsp;
		  <a href="pdfs/Emily_Jin_CV.pdf" target="_blank">CV</a> &nbsp;/&nbsp;
		  <a href="pdfs/research_statement.pdf" target="_blank">Research Statement</a> &nbsp;/&nbsp;						
                  <a href="https://scholar.google.com/citations?user=-MTq9O0AAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
<!--                   <a href="https://github.com/emilyzjin/">Github</a> &nbsp;/&nbsp; -->
                  <a href="https://www.linkedin.com/in/emily-jin-020"> LinkedIn </a>
                  <!-- <a href="https://twitter.com/emilyzjin">Twitter</a> &nbsp;/&nbsp; -->
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/headshot.png"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/headshot.png" class="hoverZoomLink"></a>
              </td>
            </tr>

	  <tr bgcolor="#e3ecff">
	      <td>
	        <h2>News</h2>
	        <p>
	          <em>I am actively applying for PhD positions starting in Fall 2025. Feel free to read more about my research below and reach out at <a href="mailto:emilyjin@stanford.edu">emilyjin@stanford.edu</a>!</em>
	        </p>
	        <p>
	          <em>I will be attending NeurIPS 2024 to present <a href="https://marple-benchmark.github.io/">MARPLE: A Benchmark for Long-Horizon Inference</a> and would love to chat!</em>
	        </p>
	      </td>
	    </tr>
		  
          </tbody></table>
	
<!-- 	<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
	  <tbody>
	      <tr bgcolor="#e3ecff">
	      <td>
	        <h2>News</h2>
	        <p>
	          <em>I am actively applying for PhD positions starting in Fall 2025. Feel free to read more about my research below and reach out at <a href="mailto:emilyjin@stanford.edu">emilyjin@stanford.edu</a>!</em>
	        </p>
	        <p>
	          <em>I will be attending NeurIPS 2024 to present <a href="https://marple-benchmark.github.io/">MARPLE: A Benchmark for Long-Horizon Inference</a> and would love to chat!</em>
	        </p>
	      </td>
	    </tr>
	  </tbody>
	</table> -->

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  My research interests lie in machine learning and computer vision, with an emphasis on visual reasoning. Inspired by human cognition, I aspire to develop machines that can perceive, understand, and reason about the visual world in ways that mirror human capabilities. In particular, I am interested in learning representations and abstractions to capture the structure inherent in the visual world, enabling AI systems to tackle complex, real-world tasks with human-like flexibility and adaptability.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
	<tr>
      <td style="padding:5%;width:30%;vertical-align:middle">
        <div class="one" style="display: grid; place-items: center;">
          <div class="two" id='scenes'><video  width=100% muted autoplay loop>
          <source src="images/scenes.png" type="image">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/scenes.png' width=100%>
        </div> 
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle">
        <a>
          <span class="papertitle">FactoredScenes: Real-World Scene Generation via Library Learning of Room Structure and Object Pose Prediction
	  </span>
        </a>
        <br>
        <a href="https://stanford.edu/~joycj/">Joy Hsu</a>,
        <strong>Emily Jin</strong>,	      
        <a href=https://jiajunwu.com/">Jiajun Wu</a>,
        <a href=https://research.adobe.com/person/niloy-mitra/">Niloy Mitra</a>,	      
        <br>
        <em>Submitted at CVPR, 2025</em>
        <p></p> 
      </td>
    </tr>
<br>
	<tr bgcolor="#e8f7f8">
      <td style="padding:5%;width:30%;vertical-align:middle">
        <div class="one" style="display: grid; place-items: center;">
          <div class="two" id='phier'><video  width=100% muted autoplay loop>
          <source src="images/phier.png" type="image">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/phier.png' width=100%>
        </div> 
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle">
        <a>
          <span class="papertitle">Predicate Hierarchies Improve Few-Shot State Classification
	  </span>
        </a>
        <br>
        <strong>Emily Jin</strong>*,
        <a href="https://stanford.edu/~joycj/">Joy Hsu</a>*,
        <a href=https://jiajunwu.com/">Jiajun Wu</a>,
        <br>
        <em>Under Review at ICLR, 2025</em>
	<br>
        <a href="https://openreview.net/pdf?id=lxu8Vz6cLs">pdf</a>
        <p></p> 
      </td>
    </tr>
<br>
    <tr bgcolor="#e8f7f8">
      <td style="padding:5%;width:30%;vertical-align:middle">
        <div class="one" style="display: grid; place-items: center;">
          <div class="two" id='marple_image'><video  width=100% muted autoplay loop>
          <source src="images/marple.png" type="image">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/marple.png' width=100%>
        </div> 
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle">
        <a href="https://marple-benchmark.github.io/">
          <span class="papertitle">MARPLE: A Benchmark for Long-Horizon Inference 
</span>
        </a>
        <br>
        <strong>Emily Jin</strong>*,
        <a href="https://www.linkedin.com/in/zhuoyi-huang">Zhuoyi Huang</a>*,
        <a href="https://janphilippfranken.github.io/">Jan-Philipp Fränken</a>,
        <a href="https://weiyuliu.com/">Weiyu Liu</a>,     
        <a href="https://www.linkedin.com/in/hannah-cha">Hannah Cha</a>,   
				<a href="https://www.erikbrockbank.com/">Erik Brockbank</a>,
        <a href="https://sarahawu.github.io/">Sarah A. Wu</a>,
        <a href="https://ai.stanford.edu/~zharu/">Ruohan Zhang</a>,
        <a href=https://jiajunwu.com/">Jiajun Wu</a>,
        <a href="https://cicl.stanford.edu/member/tobias_gerstenberg/">Tobias Gerstenberg</a> 	
        <br>
        <em>NeurIPS Datasets and Benchmarks Track, 2024</em>
        <br> 
        <a href="https://marple-benchmark.github.io/">project page</a>
        /
        <a href="https://arxiv.org/abs/2410.01926">pdf</a>
        /
        <a href="https://github.com/marple-benchmark/marple">code</a>
        <p></p> 
      </td>
    </tr>	
    <tr>
      <td style="padding:5%;width:30%;vertical-align:middle">
        <div class="one" style="display: grid; place-items: center;">
          <div class="two" id='whodunnit_image'><video  width=100% muted autoplay loop>
          <source src="images/whodunnit.png" type="image">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/whodunnit.png' width=100%>
        </div> 
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle">
        <a href="https://cicl.stanford.edu/papers/wu2024whodunnit.pdf">
          <span class="papertitle">Whodunnit? Inferring What Happened From Multimodal Evidence
</span>
        </a>
        <br>
				<a href="https://sarahawu.github.io/">Sarah A. Wu</a>*,
        <a href="https://www.erikbrockbank.com/">Erik Brockbank</a>*,
        <a href="https://www.linkedin.com/in/hannah-cha">Hannah Cha</a>,
        <a href="https://janphilippfranken.github.io/">Jan-Philipp Fränken</a>,
        <strong>Emily Jin</strong>,
        <a href="https://www.linkedin.com/in/zhuoyi-huang">Zhuoyi Huang</a>,
        <a href="https://weiyuliu.com/">Weiyu Liu</a>,
        <a href="https://ai.stanford.edu/~zharu/">Ruohan Zhang</a>,
        <a href=https://jiajunwu.com/">Jiajun Wu</a>,
        <a href="https://cicl.stanford.edu/member/tobias_gerstenberg/">Tobias Gerstenberg</a> 	
        <br>
        <em>CogSci</em>, 2024
        <br>
        <a href="https://osf.io/preprints/psyarxiv/gpzms">preprint</a>
        /
        <a href="https://cicl.stanford.edu/papers/wu2024whodunnit.pdf">pdf</a>
        /
        <a href="https://cicl.stanford.edu/posters/wu2024whodunnit-poster.pdf">poster</a>
        /
        <a href="https://github.com/cicl-stanford/whodunnit_multimodal_inference">code</a>
        <p></p> 
      </td>
    </tr>
	
    <tr>
      <td style="padding:5%;width:30%;vertical-align:middle">
        <div class="one" style="display: grid; place-items: center;">
          <div class="two" id='mini_bh_image'><video  width=100% muted autoplay loop>
          <source src="images/mini_bh.png" type="image">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/mini_bh.png' width=100%>
        </div> 
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle">
        <a href="https://github.com/StanfordVL/mini_behavior">
          <span class="papertitle">Mini-BEHAVIOR: A Procedurally Generated Benchmark for Long-horizon Decision-Making in Embodied AI
</span>
        </a>
        <br> 
        <strong>Emily Jin</strong>*,
        <a href="https://jiahenghu.github.io/">Jiaheng Hu</a>*,
        <a href="https://www.linkedin.com/in/zhuoyi-huang">Zhuoyi Huang</a>,
        <a href="https://ai.stanford.edu/~zharu/">Ruohan Zhang</a>,
        <a href="https://jiajunwu.com/">Jiajun Wu</a>,
        <a href="https://profiles.stanford.edu/fei-fei-li">Li Fei-Fei</a>,
        <a href="https://robertomartinmartin.com/"> Roberto Martín-Martín</a>
        <br>
        <em>NeurIPS GenPlan Workshop & NeurIPS ALOE Workshop</em>, 2023
        <br> 
        <a href="https://arxiv.org/abs/2310.01824">paper</a>
        /
        <a href="https://neurips.cc/media/PosterPDFs/NeurIPS%202023/79902.png?t=1702417636.9499474">poster</a>
        /
        <a href="https://github.com/StanfordVL/mini_behavior">code</a>
        <p></p> 
      </td>
    </tr> 

    <tr>
      <td style="padding:5%;width:30%;vertical-align:middle">
        <div class="one" style="display: grid; place-items: center;">
          <div class="two" id='sgm_image'><video  width=100% muted autoplay loop>
          <source src="images/sgm.png" type="image">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/sgm.png' width=100%>
        </div> 
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle">
        <a href=https://www.scenegraphmemory.com/">
          <span class="papertitle">Modeling Dynamic Environments with Scene Graph Memory
</span>
        </a>
        <br>  
        <a>Andrey Kurenkov</a>*,
        <a href="https://mlingelbach.com/">Michael Lingelbach</a>,
        <a href="https://tanmay-agarwal.com/">Tanmay Agarwal</a>,
        <strong>Emily Jin</strong>,
        <a href="https://www.chengshuli.me/">Chengshu Li</a>,
        <a href="https://ai.stanford.edu/~zharu/">Ruohan Zhang</a>,
        <a href="https://profiles.stanford.edu/fei-fei-li">Li Fei-Fei</a>,
        <a href="https://jiajunwu.com/">Jiajun Wu</a>,
        <a href="https://aicenter.stanford.edu/people/silvio-savarese">Silvio Savarese</a>
        <a href="https://robertomartinmartin.com/"> Roberto Martín-Martín</a>
        <br>
        <em>ICML</em>, 2023
        <br> 
        <a href="https://www.scenegraphmemory.com/">project page</a>
        /
        <a href="https://arxiv.org/abs/2305.17537">paper</a>
        /
        <a href="https://github.com/andreykurenkov/modeling_env_dynamics">code</a>
        <p></p> 
      </td>
    </tr> 

    <tr>
      <td style="padding:5%;width:30%;vertical-align:middle">
        <div class="one" style="display: grid; place-items: center;">
          <div class="two" id='sgm_image'><video  width=100% muted autoplay loop>
          <source src="images/moma.png" type="image">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/moma.png' width=100%>
        </div> 
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle">
        <a href="https://moma.stanford.edu/#/">
          <span class="papertitle">MOMA-LRG: Language-Refined Graphs for Multi-Object Multi-Actor Activity Parsing
</span>
        </a>
        <br>  
        <a href="https://alan.vision/"> Zelun Luo</a>,
        <a href="https://zanedurante.github.io/"> Zane Durante</a>*,
        <a href="https://linden-li.github.io/">Linden Li</a>*,
        <a>Wanze Xie</a>,
        <a>Ruochen Liu</a>,
        <strong>Emily Jin</strong>,
        <a href="https://www.linkedin.com/in/zhuoyi-huang"> Zhuoyi Huang</a>,
        <a > Lun Yu Li</a>,
        <a href="https://ai.stanford.edu/~zharu/">Ruohan Zhang</a>,
        <a href="https://jiajunwu.com/">Jiajun Wu</a>,
        <a href="https://www.niebles.net/">Juan Carlos Niebles</a>,
        <a href="https://stanford.edu/~eadeli/">Ehsan Adeli</a>        
        <a href="https://profiles.stanford.edu/fei-fei-li">Li Fei-Fei</a>,
        <br>
        <em>NeurIPS Datasets and Benchmarks Track</em>, 2022
        <br> 
        <a href="https://moma.stanford.edu/#/">project page</a>
        /
        <a href="https://papers.nips.cc/paper_files/paper/2022/hash/22c16986b2f50af520f56dc34d91e403-Abstract-Datasets_and_Benchmarks.html">paper</a>
        /
        <a href="https://github.com/StanfordVL/moma/">code</a>
        <p></p> 
      </td>
    </tr>     

    </tbody></table>

          
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Teaching & Outreach</h2>
		<p>
			As a young woman in STEM, I am incredibly grateful for the diverse opportunities, inspiring mentors, and inclusive communities that have supported me over the years. These experiences fuel my passion for empowering others through teaching and outreach. Here are some of the most meaningful experiences I have had:
		</p>
		<br>		      
                <a href="https://hai.stanford.edu/stanford-ai4all">
                  Stanford AI4ALL.
                </a>A summer program designed to ignite students' passion for AI by exposing them to cutting-edge advancements in the field —- just as it sparked my own interest when I attended it in high school.
                <br>
                Program Manager, 2020-Present.

                <br><br>
		      
                <a href="https://hai.stanford.edu/stanford-ai4all">
                  Stanford CS 157.
                </a>Introduction to Logic.
                <br>
                Course Assistant, Fall 2024.

                <br><br>

                <a href="https://aihacks.com">
                  AIHacks.
                </a>Southern California's first all-female high school hackathon.
                <br>
                Founder and Executive Director, 2019-2020 
                <br>
                Media: <a href="https://spectrumnews1.com/ca/la-west/news/2019/06/17/student-organizes-all-female-hackathon-to-address-ai-gender-gap#">Spectrum News</a>
                /
                <a href="https://www.dailynews.com/2019/06/17/a-north-hollywood-high-school-seniors-all-girl-hackathon-aimed-to-empower-her-peers/">Los Angeles Daily News</a>
              </td>
            </tr> 

          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Website source from <a href="https://jonbarron.info/">Jon Barron</a>. 
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
